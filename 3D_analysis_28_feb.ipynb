{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width 3840\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 55\u001b[0m\n\u001b[0;32m     51\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     53\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mNeurotech\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnandini data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnewoutput_new_nandini.avi\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 55\u001b[0m \u001b[43mcreate_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 42\u001b[0m, in \u001b[0;36mcreate_video\u001b[1;34m(video_path)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Convert depth image back to RGB\u001b[39;00m\n\u001b[0;32m     40\u001b[0m depth_img_clahe \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(depth_clahe, cv2\u001b[38;5;241m.\u001b[39mCOLOR_GRAY2RGB)\n\u001b[1;32m---> 42\u001b[0m \u001b[43mout_depth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepth_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_RGB2BGR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m out_rgb\u001b[38;5;241m.\u001b[39mwrite(cv2\u001b[38;5;241m.\u001b[39mcvtColor(rgb_img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR))\n\u001b[0;32m     44\u001b[0m out_clahe_depth\u001b[38;5;241m.\u001b[39mwrite(cv2\u001b[38;5;241m.\u001b[39mcvtColor(depth_img_clahe, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_video(video_path):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Couldn't open the video file.\")\n",
    "        return\n",
    "\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    print(\"width\", width)\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    out_rgb = cv2.VideoWriter(r'C:\\Users\\Neurotech\\Downloads\\nandini data\\rgb_img.avi', cv2.VideoWriter_fourcc(*'XVID'), frame_rate, (int(width/2), height))\n",
    "    out_clahe_depth = cv2.VideoWriter(r'C:\\Users\\Neurotech\\Downloads\\nandini data\\depth_clahe_img.avi', cv2.VideoWriter_fourcc(*'XVID'), frame_rate, (int(width/2), height))\n",
    "    out_depth = cv2.VideoWriter(r'C:\\Users\\Neurotech\\Downloads\\nandini data\\depth_img.avi', cv2.VideoWriter_fourcc(*'XVID'), frame_rate, (int(width/2), height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        rgb_img = frame_rgb[:, :int(width/2), :]\n",
    "        depth_img = frame_rgb[:, int(width/2):, :]\n",
    "\n",
    "        # Convert depth image to grayscale\n",
    "        depth_gray = cv2.cvtColor(depth_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Apply CLAHE to enhance contrast\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        depth_clahe = clahe.apply(depth_gray)\n",
    "\n",
    "        # Convert depth image back to RGB\n",
    "        depth_img_clahe = cv2.cvtColor(depth_clahe, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        out_depth.write(cv2.cvtColor(depth_gray, cv2.COLOR_RGB2BGR))\n",
    "        out_rgb.write(cv2.cvtColor(rgb_img, cv2.COLOR_RGB2BGR))\n",
    "        out_clahe_depth.write(cv2.cvtColor(depth_img_clahe, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    cap.release()\n",
    "    out_rgb.release()\n",
    "    out_depth.release()\n",
    "    out_clahe_depth.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "video_path = r\"C:\\Users\\Neurotech\\Downloads\\nandini data\\newoutput_new_nandini.avi\"\n",
    "\n",
    "create_video(video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 2)\n"
     ]
    }
   ],
   "source": [
    "kps = np.load(r\"C:\\Users\\Neurotech\\Downloads\\nandini data\\joint_kps_nandini.npy\")\n",
    "print(kps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
